{
  "id": "57e36fa0-9f09-4a7f-95c1-64aa1f1e6622",
  "source_type": "article",
  "source_url": "https://docs.litellm.ai/docs/ocr",
  "source_file_path": null,
  "title": "Ocr",
  "authors": [],
  "created_at": "2026-01-01T20:31:34.032879",
  "ingested_at": "2026-01-01T20:31:34.033016",
  "full_text": "Title: /ocr | liteLLM\n\nURL Source: https://docs.litellm.ai/docs/ocr\n\nPublished Time: Fri, 02 Jan 2026 04:28:16 GMT\n\nMarkdown Content:\n| Feature | Supported |\n| --- | --- |\n| Cost Tracking | \u2705 |\n| Logging | \u2705 (Basic Logging not supported) |\n| Load Balancing | \u2705 |\n| Supported Providers | `mistral`, `azure_ai`, `vertex_ai` |\n\ntip\n\n**LiteLLM Python SDK Usage**[\u200b](https://docs.litellm.ai/docs/ocr#litellm-python-sdk-usage \"Direct link to litellm-python-sdk-usage\")\n------------------------------------------------------------------------------------------------------------------------------------\n\n### Quick Start[\u200b](https://docs.litellm.ai/docs/ocr#quick-start \"Direct link to Quick Start\")\n\n`from litellm import ocrimport osos.environ[\"MISTRAL_API_KEY\"] = \"sk-..\"response = ocr(    model=\"mistral/mistral-ocr-latest\",    document={        \"type\": \"document_url\",        \"document_url\": \"https://arxiv.org/pdf/2201.04234\"    })# Access extracted textfor page in response.pages:    print(f\"Page {page.index}:\")    print(page.markdown)`\n\n### Async Usage[\u200b](https://docs.litellm.ai/docs/ocr#async-usage \"Direct link to Async Usage\")\n\n`from litellm import aocrimport os, asyncioos.environ[\"MISTRAL_API_KEY\"] = \"sk-..\"async def test_async_ocr():     response = await aocr(        model=\"mistral/mistral-ocr-latest\",        document={            \"type\": \"document_url\",            \"document_url\": \"https://arxiv.org/pdf/2201.04234\"        }    )        # Access extracted text    for page in response.pages:        print(f\"Page {page.index}:\")        print(page.markdown)asyncio.run(test_async_ocr())`\n\n### Using Base64 Encoded Documents[\u200b](https://docs.litellm.ai/docs/ocr#using-base64-encoded-documents \"Direct link to Using Base64 Encoded Documents\")\n\n`import base64from litellm import ocr# Encode PDF to base64with open(\"document.pdf\", \"rb\") as f:    base64_pdf = base64.b64encode(f.read()).decode('utf-8')response = ocr(    model=\"mistral/mistral-ocr-latest\",    document={        \"type\": \"document_url\",        \"document_url\": f\"data:application/pdf;base64,{base64_pdf}\"    })`\n\n### Optional Parameters[\u200b](https://docs.litellm.ai/docs/ocr#optional-parameters \"Direct link to Optional Parameters\")\n\n`response = ocr(    model=\"mistral/mistral-ocr-latest\",    document={        \"type\": \"document_url\",        \"document_url\": \"https://example.com/doc.pdf\"    },    # Optional Mistral parameters    pages=[0, 1, 2],              # Only process specific pages    include_image_base64=True,     # Include extracted images    image_limit=10,                # Max images to return    image_min_size=100             # Min image size to include)`\n\n**LiteLLM Proxy Usage**[\u200b](https://docs.litellm.ai/docs/ocr#litellm-proxy-usage \"Direct link to litellm-proxy-usage\")\n---------------------------------------------------------------------------------------------------------------------\n\nLiteLLM provides a Mistral API compatible `/ocr` endpoint for OCR calls.\n\n**Setup**\n\nAdd this to your litellm proxy config.yaml\n\n`model_list:  - model_name: mistral-ocr    litellm_params:      model: mistral/mistral-ocr-latest      api_key: os.environ/MISTRAL_API_KEY`\n\nStart litellm\n\n`litellm --config /path/to/config.yaml# RUNNING on http://0.0.0.0:4000`\n\nTest request\n\n`curl http://0.0.0.0:4000/v1/ocr \\  -H \"Authorization: Bearer sk-1234\" \\  -H \"Content-Type: application/json\" \\  -d '{    \"model\": \"mistral-ocr\",    \"document\": {        \"type\": \"document_url\",        \"document_url\": \"https://arxiv.org/pdf/2201.04234\"    }  }'`\n\n**Request/Response Format**[\u200b](https://docs.litellm.ai/docs/ocr#requestresponse-format \"Direct link to requestresponse-format\")\n-------------------------------------------------------------------------------------------------------------------------------\n\n### Example Request[\u200b](https://docs.litellm.ai/docs/ocr#example-request \"Direct link to Example Request\")\n\n`{    \"model\": \"mistral/mistral-ocr-latest\",    \"document\": {        \"type\": \"document_url\",        \"document_url\": \"https://arxiv.org/pdf/2201.04234\"    },    \"pages\": [0, 1, 2],              # Optional: specific pages to process    \"include_image_base64\": True,     # Optional: include extracted images    \"image_limit\": 10,                # Optional: max images to return    \"image_min_size\": 100             # Optional: min image size in pixels}`\n\n### Request Parameters[\u200b](https://docs.litellm.ai/docs/ocr#request-parameters \"Direct link to Request Parameters\")\n\n| Parameter | Type | Required | Description |\n| --- | --- | --- | --- |\n| `model` | string | Yes | The OCR model to use (e.g., `\"mistral/mistral-ocr-latest\"`) |\n| `document` | object | Yes | Document to process. Must contain `type` and URL field |\n| `document.type` | string | Yes | Either `\"document_url\"` for PDFs/docs or `\"image_url\"` for images |\n| `document.document_url` | string | Conditional | URL to the document (required if `type` is `\"document_url\"`) |\n| `document.image_url` | string | Conditional | URL to the image (required if `type` is `\"image_url\"`) |\n| `pages` | array | No | List of specific page indices to process (0-indexed) |\n| `include_image_base64` | boolean | No | Whether to include extracted images as base64 strings |\n| `image_limit` | integer | No | Maximum number of images to return |\n| `image_min_size` | integer | No | Minimum size (in pixels) for images to include |\n\n#### Document Format Examples[\u200b](https://docs.litellm.ai/docs/ocr#document-format-examples \"Direct link to Document Format Examples\")\n\n**For PDFs and documents:**\n\n`{  \"type\": \"document_url\",  \"document_url\": \"https://example.com/document.pdf\"}`\n\n**For images:**\n\n`{  \"type\": \"image_url\",  \"image_url\": \"https://example.com/image.png\"}`\n\n**For base64-encoded content:**\n\n`{  \"type\": \"document_url\",  \"document_url\": \"data:application/pdf;base64,JVBERi0xLjQKJ...\"}`\n\n### Response Format[\u200b](https://docs.litellm.ai/docs/ocr#response-format \"Direct link to Response Format\")\n\nThe response follows Mistral's OCR format with the following structure:\n\n`{  \"pages\": [    {      \"index\": 0,      \"markdown\": \"# Document Title\\n\\nExtracted text content...\",      \"dimensions\": {        \"dpi\": 200,        \"height\": 2200,        \"width\": 1700      },      \"images\": [        {          \"image_base64\": \"base64string...\",          \"bbox\": {            \"x\": 100,            \"y\": 200,            \"width\": 300,            \"height\": 400          }        }      ]    }  ],  \"model\": \"mistral-ocr-2505-completion\",  \"usage_info\": {    \"pages_processed\": 29,    \"doc_size_bytes\": 3002783  },  \"document_annotation\": null,  \"object\": \"ocr\"}`\n\n#### Response Fields[\u200b](https://docs.litellm.ai/docs/ocr#response-fields \"Direct link to Response Fields\")\n\n| Field | Type | Description |\n| --- | --- | --- |\n| `pages` | array | List of processed pages with extracted content |\n| `pages[].index` | integer | Page number (0-indexed) |\n| `pages[].markdown` | string | Extracted text in Markdown format |\n| `pages[].dimensions` | object | Page dimensions (dpi, height, width in pixels) |\n| `pages[].images` | array | Extracted images from the page (if `include_image_base64=true`) |\n| `model` | string | The model used for OCR processing |\n| `usage_info` | object | Processing statistics (pages processed, document size) |\n| `document_annotation` | object | Optional document-level annotations |\n| `object` | string | Always `\"ocr\"` for OCR responses |\n\n**Supported Providers**[\u200b](https://docs.litellm.ai/docs/ocr#supported-providers \"Direct link to supported-providers\")\n---------------------------------------------------------------------------------------------------------------------\n\n| Provider | Link to Usage |\n| --- | --- |\n| Mistral AI | [Usage](https://docs.litellm.ai/docs/ocr#quick-start) |\n| Azure AI | [Usage](https://docs.litellm.ai/docs/providers/azure_ocr) |\n| Vertex AI | [Usage](https://docs.litellm.ai/docs/providers/vertex_ocr) |\n",
  "annotations": [],
  "raw_file_hash": null,
  "asset_paths": [],
  "processing_status": "pending",
  "error_message": null,
  "obsidian_path": null,
  "tags": [],
  "metadata": {
    "source_url": "https://docs.litellm.ai/docs/ocr",
    "format": "markdown",
    "source": "jina_reader",
    "markdown": "Title: /ocr | liteLLM\n\nURL Source: https://docs.litellm.ai/docs/ocr\n\nPublished Time: Fri, 02 Jan 2026 04:28:16 GMT\n\nMarkdown Content:\n| Feature | Supported |\n| --- | --- |\n| Cost Tracking | \u2705 |\n| Logging | \u2705 (Basic Logging not supported) |\n| Load Balancing | \u2705 |\n| Supported Providers | `mistral`, `azure_ai`, `vertex_ai` |\n\ntip\n\n**LiteLLM Python SDK Usage**[\u200b](https://docs.litellm.ai/docs/ocr#litellm-python-sdk-usage \"Direct link to litellm-python-sdk-usage\")\n------------------------------------------------------------------------------------------------------------------------------------\n\n### Quick Start[\u200b](https://docs.litellm.ai/docs/ocr#quick-start \"Direct link to Quick Start\")\n\n`from litellm import ocrimport osos.environ[\"MISTRAL_API_KEY\"] = \"sk-..\"response = ocr(    model=\"mistral/mistral-ocr-latest\",    document={        \"type\": \"document_url\",        \"document_url\": \"https://arxiv.org/pdf/2201.04234\"    })# Access extracted textfor page in response.pages:    print(f\"Page {page.index}:\")    print(page.markdown)`\n\n### Async Usage[\u200b](https://docs.litellm.ai/docs/ocr#async-usage \"Direct link to Async Usage\")\n\n`from litellm import aocrimport os, asyncioos.environ[\"MISTRAL_API_KEY\"] = \"sk-..\"async def test_async_ocr():     response = await aocr(        model=\"mistral/mistral-ocr-latest\",        document={            \"type\": \"document_url\",            \"document_url\": \"https://arxiv.org/pdf/2201.04234\"        }    )        # Access extracted text    for page in response.pages:        print(f\"Page {page.index}:\")        print(page.markdown)asyncio.run(test_async_ocr())`\n\n### Using Base64 Encoded Documents[\u200b](https://docs.litellm.ai/docs/ocr#using-base64-encoded-documents \"Direct link to Using Base64 Encoded Documents\")\n\n`import base64from litellm import ocr# Encode PDF to base64with open(\"document.pdf\", \"rb\") as f:    base64_pdf = base64.b64encode(f.read()).decode('utf-8')response = ocr(    model=\"mistral/mistral-ocr-latest\",    document={        \"type\": \"document_url\",        \"document_url\": f\"data:application/pdf;base64,{base64_pdf}\"    })`\n\n### Optional Parameters[\u200b](https://docs.litellm.ai/docs/ocr#optional-parameters \"Direct link to Optional Parameters\")\n\n`response = ocr(    model=\"mistral/mistral-ocr-latest\",    document={        \"type\": \"document_url\",        \"document_url\": \"https://example.com/doc.pdf\"    },    # Optional Mistral parameters    pages=[0, 1, 2],              # Only process specific pages    include_image_base64=True,     # Include extracted images    image_limit=10,                # Max images to return    image_min_size=100             # Min image size to include)`\n\n**LiteLLM Proxy Usage**[\u200b](https://docs.litellm.ai/docs/ocr#litellm-proxy-usage \"Direct link to litellm-proxy-usage\")\n---------------------------------------------------------------------------------------------------------------------\n\nLiteLLM provides a Mistral API compatible `/ocr` endpoint for OCR calls.\n\n**Setup**\n\nAdd this to your litellm proxy config.yaml\n\n`model_list:  - model_name: mistral-ocr    litellm_params:      model: mistral/mistral-ocr-latest      api_key: os.environ/MISTRAL_API_KEY`\n\nStart litellm\n\n`litellm --config /path/to/config.yaml# RUNNING on http://0.0.0.0:4000`\n\nTest request\n\n`curl http://0.0.0.0:4000/v1/ocr \\  -H \"Authorization: Bearer sk-1234\" \\  -H \"Content-Type: application/json\" \\  -d '{    \"model\": \"mistral-ocr\",    \"document\": {        \"type\": \"document_url\",        \"document_url\": \"https://arxiv.org/pdf/2201.04234\"    }  }'`\n\n**Request/Response Format**[\u200b](https://docs.litellm.ai/docs/ocr#requestresponse-format \"Direct link to requestresponse-format\")\n-------------------------------------------------------------------------------------------------------------------------------\n\n### Example Request[\u200b](https://docs.litellm.ai/docs/ocr#example-request \"Direct link to Example Request\")\n\n`{    \"model\": \"mistral/mistral-ocr-latest\",    \"document\": {        \"type\": \"document_url\",        \"document_url\": \"https://arxiv.org/pdf/2201.04234\"    },    \"pages\": [0, 1, 2],              # Optional: specific pages to process    \"include_image_base64\": True,     # Optional: include extracted images    \"image_limit\": 10,                # Optional: max images to return    \"image_min_size\": 100             # Optional: min image size in pixels}`\n\n### Request Parameters[\u200b](https://docs.litellm.ai/docs/ocr#request-parameters \"Direct link to Request Parameters\")\n\n| Parameter | Type | Required | Description |\n| --- | --- | --- | --- |\n| `model` | string | Yes | The OCR model to use (e.g., `\"mistral/mistral-ocr-latest\"`) |\n| `document` | object | Yes | Document to process. Must contain `type` and URL field |\n| `document.type` | string | Yes | Either `\"document_url\"` for PDFs/docs or `\"image_url\"` for images |\n| `document.document_url` | string | Conditional | URL to the document (required if `type` is `\"document_url\"`) |\n| `document.image_url` | string | Conditional | URL to the image (required if `type` is `\"image_url\"`) |\n| `pages` | array | No | List of specific page indices to process (0-indexed) |\n| `include_image_base64` | boolean | No | Whether to include extracted images as base64 strings |\n| `image_limit` | integer | No | Maximum number of images to return |\n| `image_min_size` | integer | No | Minimum size (in pixels) for images to include |\n\n#### Document Format Examples[\u200b](https://docs.litellm.ai/docs/ocr#document-format-examples \"Direct link to Document Format Examples\")\n\n**For PDFs and documents:**\n\n`{  \"type\": \"document_url\",  \"document_url\": \"https://example.com/document.pdf\"}`\n\n**For images:**\n\n`{  \"type\": \"image_url\",  \"image_url\": \"https://example.com/image.png\"}`\n\n**For base64-encoded content:**\n\n`{  \"type\": \"document_url\",  \"document_url\": \"data:application/pdf;base64,JVBERi0xLjQKJ...\"}`\n\n### Response Format[\u200b](https://docs.litellm.ai/docs/ocr#response-format \"Direct link to Response Format\")\n\nThe response follows Mistral's OCR format with the following structure:\n\n`{  \"pages\": [    {      \"index\": 0,      \"markdown\": \"# Document Title\\n\\nExtracted text content...\",      \"dimensions\": {        \"dpi\": 200,        \"height\": 2200,        \"width\": 1700      },      \"images\": [        {          \"image_base64\": \"base64string...\",          \"bbox\": {            \"x\": 100,            \"y\": 200,            \"width\": 300,            \"height\": 400          }        }      ]    }  ],  \"model\": \"mistral-ocr-2505-completion\",  \"usage_info\": {    \"pages_processed\": 29,    \"doc_size_bytes\": 3002783  },  \"document_annotation\": null,  \"object\": \"ocr\"}`\n\n#### Response Fields[\u200b](https://docs.litellm.ai/docs/ocr#response-fields \"Direct link to Response Fields\")\n\n| Field | Type | Description |\n| --- | --- | --- |\n| `pages` | array | List of processed pages with extracted content |\n| `pages[].index` | integer | Page number (0-indexed) |\n| `pages[].markdown` | string | Extracted text in Markdown format |\n| `pages[].dimensions` | object | Page dimensions (dpi, height, width in pixels) |\n| `pages[].images` | array | Extracted images from the page (if `include_image_base64=true`) |\n| `model` | string | The model used for OCR processing |\n| `usage_info` | object | Processing statistics (pages processed, document size) |\n| `document_annotation` | object | Optional document-level annotations |\n| `object` | string | Always `\"ocr\"` for OCR responses |\n\n**Supported Providers**[\u200b](https://docs.litellm.ai/docs/ocr#supported-providers \"Direct link to supported-providers\")\n---------------------------------------------------------------------------------------------------------------------\n\n| Provider | Link to Usage |\n| --- | --- |\n| Mistral AI | [Usage](https://docs.litellm.ai/docs/ocr#quick-start) |\n| Azure AI | [Usage](https://docs.litellm.ai/docs/providers/azure_ocr) |\n| Vertex AI | [Usage](https://docs.litellm.ai/docs/providers/vertex_ocr) |\n"
  }
}