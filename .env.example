# =============================================================================
# Second Brain - Environment Variables
# =============================================================================
#
# INSTRUCTIONS:
#   1. Copy this file to .env: cp .env.example .env
#   2. Fill in the required values (marked with REQUIRED)
#   3. Adjust optional values as needed
#
# SECURITY:
#   - NEVER commit .env to version control
#   - .env is already in .gitignore
#   - This file (.env.example) is safe to commit as it contains no real secrets
#
# For detailed configuration options, see:
#   - backend/app/config/settings.py (Python settings)
#   - config/default.yaml (Application behavior config)
#
# =============================================================================

# =============================================================================
# DATA DIRECTORY (REQUIRED)
# =============================================================================
# Root directory for all persistent data:
#   ${DATA_DIR}/
#   ├── postgres/   - PostgreSQL data
#   ├── redis/      - Redis AOF files
#   ├── neo4j/      - Neo4j graph database
#   └── obsidian/   - Obsidian vault (notes, templates)
#
# Tip: Use absolute paths to avoid confusion

DATA_DIR=~/workspace/obsidian/second_brain

# =============================================================================
# POSTGRESQL (REQUIRED)
# =============================================================================
# Stores: learning records, content metadata, cost tracking

POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_USER=secondbrain
POSTGRES_PASSWORD=your_secure_postgres_password_here
POSTGRES_DB=secondbrain

# =============================================================================
# REDIS
# =============================================================================
# Stores: session cache, Celery task queues

REDIS_URL=redis://localhost:6379/0

# Celery configuration (defaults to Redis)
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/1

# =============================================================================
# NEO4J (REQUIRED for knowledge graph features)
# =============================================================================
# Stores: concept relationships, knowledge graph

NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=your_secure_neo4j_password_here

# =============================================================================
# OBSIDIAN VAULT
# =============================================================================
# Path to Obsidian vault. In Docker, use /vault (mounted volume).
# For local development, use your actual vault path.

OBSIDIAN_VAULT_PATH=/vault

# =============================================================================
# FILE UPLOADS
# =============================================================================
# Temporary staging directory for file uploads before processing.
# Files move to vault assets/ only after successful processing.

UPLOAD_DIR=/tmp/second_brain_uploads

# =============================================================================
# LLM API KEYS (at least one required for LLM features)
# =============================================================================
# Get your API keys from:
#   - OpenAI: https://platform.openai.com/api-keys
#   - Anthropic: https://console.anthropic.com/settings/keys
#   - Mistral: https://console.mistral.ai/api-keys

# OpenAI - Used for: text completion, embeddings
OPENAI_API_KEY=sk-your_openai_api_key_here

# Anthropic - Used for: text completion
ANTHROPIC_API_KEY=sk-ant-your_anthropic_api_key_here

# Gemini (Google AI) - Used for: text completion, vision
#   Get key: https://aistudio.google.com/apikey
GEMINI_API_KEY=

# Mistral - Used for: OCR (Pixtral), text completion
MISTRAL_API_KEY=your_mistral_api_key_here

# =============================================================================
# LLM MODEL CONFIGURATION
# =============================================================================
# Model identifiers use LiteLLM format: provider/model-name
# See: https://docs.litellm.ai/docs/providers

# Vision model for OCR (document/image text extraction)
# Options: mistral/mistral-ocr-2512, openai/gpt-4o, anthropic/claude-sonnet-4-20250514
OCR_MODEL=mistral/mistral-ocr-2512
OCR_MAX_TOKENS=4000
OCR_USE_JSON_MODE=true

# Text model for metadata inference, note expansion, analysis
# Options: gemini/gemini-3-flash-preview, openai/gpt-4o-mini, anthropic/claude-sonnet-4-20250514
TEXT_MODEL=gemini/gemini-3-flash-preview

# =============================================================================
# LLM BUDGET & COST MANAGEMENT
# =============================================================================
# LiteLLM tracks spending; set budgets to prevent runaway costs

LITELLM_BUDGET_MAX=100.0
LITELLM_BUDGET_ALERT=80.0

# =============================================================================
# PIPELINE SETTINGS
# =============================================================================
# PDF processing
PDF_HANDWRITING_DETECTION=true
PDF_IMAGE_DPI=300
PDF_MAX_FILE_SIZE_MB=50

# Voice transcription
VOICE_EXPAND_NOTES=true

# =============================================================================
# EXTERNAL API TOKENS (Optional)
# =============================================================================
# For syncing bookmarks and starred repos

# Raindrop.io - Bookmark sync
# Get token: https://app.raindrop.io/settings/integrations
RAINDROP_ACCESS_TOKEN=

# GitHub - Starred repo import
# Create token: https://github.com/settings/tokens (needs 'repo' scope)
GITHUB_ACCESS_TOKEN=

# =============================================================================
# OBSERVABILITY (Optional)
# =============================================================================
# Langfuse for LLM observability (traces, evaluations)
# See: https://langfuse.com/docs

LANGFUSE_ENABLED=false
# LANGFUSE_PUBLIC_KEY=
# LANGFUSE_SECRET_KEY=
# LANGFUSE_HOST=https://cloud.langfuse.com

# =============================================================================
# APPLICATION SETTINGS
# =============================================================================

# Application name (shown in logs, health endpoints)
APP_NAME=Second Brain

# Debug mode (enables verbose logging, detailed errors)
# WARNING: Set to false in production!
DEBUG=false

# =============================================================================
# FRONTEND (Vite)
# =============================================================================
# These are read by the frontend build process (not Python)

VITE_API_URL=http://localhost:8000
